## 引言
在数据量不大的时候, 我们在处理结构化数据时, 会优先考虑MySQL/Postgres等传统的关系型数据库, 但是随着项目的发展, 数据量越来越多, 传统的关系型数据库在处理数据时, 会出现性能瓶颈, 这时候, 我们开始考虑使用Hadoop等分布式系统来解决性能问题. 
在实际项目使用中, 使用hive可以解决大多数问题, 但在有些特殊场景, 使用hive就显得比较麻烦. 
## 背景
接下来, 我就遇到的情况作下介绍:
在做玩家会话相关特征的统计计算时, 需要通过自关联大表来做一些统计, 但是由于数据量过于庞大, hive脚本始终无法执行完成. 重新梳理逻辑后, 发现UDAF函数可以解决自关联的情况, 在编写了hive的UDAF代码后, 部署却遇到了问题, 原因是hive在执行时, 需要修改uber系统级的参数, 为了避免这个情况, 考虑使用spark来完成相关特征的计算.
## 过程
###### 下载
从官网下载spark, 由于公司使用的是Hadoop 2.6, 因此下载基于Hadoop 2.6的spark二进制包, 我选择下载2.4版本的spark
###### 安装
1. 将二进制包解压至任一目录
2. 将集群环境中的hive/yarn相关的配置文件, 拷贝至spark安装目录下的conf文件夹
###### 开发
1. 开发相关的逻辑处理代码
2. 将代码打成jar包
###### 部署
1. 将jar包上传至服务器
2. 执行调用命令, 利用数据仓库集群的数据和计算资源, 计算相关特征
## 总结
在实际使用中, 我使用了spark2.4, 其对应的hive版本为1.3+, 需要注意在调用中, 一定要在调用命令中指定hive版本以及相对应的hive库
spark2.4 使用了jdk8编译了相关的库, 而集群的Hadoop是基于jdk7编译的, 如果不指定jdk版本的话, 集群是无法执行代码的.
